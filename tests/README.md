# Grid Guardian - Testing Suite

Comprehensive automated test suite for the Grid Guardian predictive maintenance system.

## ğŸ“Š Test Statistics

- **Total Tests**: 92
- **Test Files**: 6
- **Test Classes**: 31+
- **Coverage**: App, Data, and Source modules

## ğŸ—‚ï¸ Test Files

### 1. test_data_validation.py
Validates data integrity and quality.

**Test Classes**:
- `TestDataFilesExist`: File existence checks
- `TestTelemetryDataStructure`: Data structure validation
- `TestNumericColumnsRanges`: Value range verification
- `TestEquipmentCoverage`: Equipment count validation
- `TestFeaturesData`: Feature engineering validation
- `TestLocationData`: Geographic data validation

**Key Validations**:
- âœ… 876,000 telemetry records
- âœ… 50 equipment units
- âœ… 18 raw sensor columns
- âœ… 95 engineered features
- âœ… Risk distribution (75%/20%/5%)

### 2. test_integration.py
End-to-end pipeline testing.

**Test Classes**:
- `TestDataPipeline`: Data processing workflow
- `TestRiskCalculation`: Risk level computation
- `TestEquipmentAggregation`: Data aggregation
- `TestStratifiedSampling`: Sampling strategy
- `TestLocationDataIntegration`: Geographic integration
- `TestModelIntegration`: ML model loading
- `TestEndToEnd`: Complete pipeline

**Key Validations**:
- âœ… Raw data â†’ Preprocessing â†’ Features
- âœ… Risk calculation consistency
- âœ… Proportional sampling maintains distribution
- âœ… Location data merges correctly

### 3. test_performance.py
Performance benchmarks and optimization tests.

**Test Classes**:
- `TestDataLoadingPerformance`: Load time benchmarks
- `TestAggregationPerformance`: Aggregation speed
- `TestMemoryUsage`: Memory efficiency
- `TestQueryPerformance`: Filter performance
- `TestScalability`: Large dataset handling
- `TestCachingEffectiveness`: Cache performance

**Benchmarks**:
- âœ… CSV loading: < 5 seconds
- âœ… Aggregations: < 2 seconds
- âœ… Filters: < 0.2 seconds
- âœ… Memory: < 500MB for sample data

### 4. test_streamlit_app.py
Streamlit application structure and health.

**Test Classes**:
- `TestPageFiles`: Page existence
- `TestPageSyntax`: Python syntax validation
- `TestRequiredDependencies`: Package availability
- `TestHomePage`: Main dashboard tests
- `TestPredictionsPage`: ML predictions page
- `TestMapsPage`: Geographic visualization
- `TestPageStructure`: UI structure
- `TestRussianLanguage`: Localization (old)
- `TestFileEncoding`: UTF-8 validation

**Key Validations**:
- âœ… All 4 pages exist and load
- âœ… No syntax errors
- âœ… All dependencies installed
- âœ… Caching implemented
- âœ… Russian text throughout

### 5. test_russian_language.py â­ NEW
Russian language UI consistency.

**Test Classes**:
- `TestRussianLanguage`: Localization verification

**Tests**:
- âœ… Cyrillic characters present in all pages
- âœ… No untranslated English UI strings
- âœ… Russian titles in st.title()
- âœ… Russian metrics in st.metric()
- âœ… UTF-8 encoding on all files

### 6. test_model_validation.py â­ NEW
Machine learning model structure.

**Test Classes**:
- `TestModelValidation`: ML model integrity

**Tests**:
- âœ… Models directory exists
- âœ… Training scripts present (train_xgboost.py, train_lstm.py)
- âœ… Script syntax validation
- âœ… Required imports (xgboost, tensorflow, pandas)
- âš ï¸ Saved models (skipped if not trained)

## ğŸš€ Quick Start

### Run All Tests
```bash
python run_tests.py
```

This will:
1. Run all 92 tests
2. Generate HTML test report
3. Generate coverage report
4. Create test log

### Manual Test Execution

#### All Tests
```bash
pytest tests/ -v
```

#### Specific Test File
```bash
pytest tests/test_data_validation.py -v
```

#### Specific Test Class
```bash
pytest tests/test_integration.py::TestRiskCalculation -v
```

#### Specific Test
```bash
pytest tests/test_performance.py::TestDataLoadingPerformance::test_csv_loading_speed -v
```

## ğŸ·ï¸ Test Markers

Tests are organized with markers for selective execution:

```bash
# Skip slow tests (good for quick checks)
pytest -m "not slow"

# Only integration tests
pytest -m integration

# Only performance tests
pytest -m performance

# Only data validation tests
pytest -m data
```

**Available Markers**:
- `unit`: Unit tests
- `integration`: Integration tests
- `slow`: Slow tests (>5 seconds)
- `data`: Data validation tests
- `ml`: Machine learning tests
- `ui`: UI/UX tests
- `performance`: Performance tests

## ğŸ“ˆ Generated Reports

After running tests, find reports in `tests/reports/`:

### 1. HTML Test Report
**File**: `tests/reports/test_report.html`

Open in browser:
```bash
start tests/reports/test_report.html
```

Contains:
- Test execution summary
- Pass/fail status for each test
- Execution time
- Error details (if any)

### 2. Coverage Report
**File**: `tests/reports/coverage/index.html`

Open in browser:
```bash
start tests/reports/coverage/index.html
```

Contains:
- Line coverage by module
- Missing lines highlighted
- Function and class coverage

### 3. Test Log
**File**: `tests/reports/test.log`

Contains:
- Detailed test execution log
- DEBUG level information
- Timestamps

### 4. Coverage XML
**File**: `coverage.xml`

For CI/CD integration (Jenkins, GitLab CI, etc.)

## ğŸ“‹ Test Results Summary

Latest run (2025-12-12):

| Test Module | Tests | Passed | Skipped | Failed |
|-------------|-------|--------|---------|--------|
| test_data_validation.py | 24 | 24 | 0 | 0 |
| test_integration.py | 11 | 10 | 1 | 0 |
| test_performance.py | 11 | 10 | 1 | 0 |
| test_streamlit_app.py | 17 | 17 | 0 | 0 |
| test_russian_language.py | 5 | 5 | 0 | 0 |
| test_model_validation.py | 8 | 5 | 3 | 0 |
| **TOTAL** | **92** | **87** | **5** | **0** |

**Status**: âœ… **ALL TESTS PASSING**

## âš ï¸ Skipped Tests

Some tests are skipped when prerequisites aren't met:

1. **Model Integration** (1 test)
   - Reason: Models not trained
   - Enable: Run `python models/train_xgboost.py`

2. **Parquet Loading Performance** (1 test)
   - Reason: Corrupted parquet file
   - Fix: Run `python data/generate_data.py`

3. **Model File Structure** (3 tests)
   - Reason: No saved models
   - Enable: Train models first

## ğŸ› ï¸ Configuration

### pytest.ini
Main pytest configuration file with:
- Test discovery paths
- Coverage settings
- HTML report generation
- Log configuration
- Warning filters

### conftest.py
Shared fixtures for all tests:
- `project_root`: Project directory
- `app_dir`: App directory
- `data_dir`: Data directory
- `models_dir`: Models directory
- `telemetry_data`: Telemetry dataset
- `sample_features`: Sample features
- `app_pages`: All Streamlit pages

## ğŸ”§ Troubleshooting

### pytest not found
```bash
pip install pytest pytest-cov pytest-html
```

### Import errors
```bash
pip install -r requirements.txt
```

### Coverage not working
```bash
# Install coverage package
pip install coverage pytest-cov

# Run with explicit coverage
pytest --cov=app --cov=data --cov=src
```

### Permission errors (Windows)
```bash
# Run without coverage
pytest tests/ --no-cov
```

### Slow test execution
```bash
# Skip slow tests
pytest -m "not slow"

# Run specific fast tests
pytest tests/test_streamlit_app.py
```

## ğŸ“¦ CI/CD Integration

### GitHub Actions
```yaml
- name: Run tests
  run: |
    pip install -r requirements.txt
    pytest tests/ --cov=app --cov=data --cov=src --html=test_report.html
```

### GitLab CI
```yaml
test:
  script:
    - pip install -r requirements.txt
    - pytest tests/ --cov-report=xml --html=test_report.html
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
```

## ğŸ¯ Best Practices

1. **Run tests before committing**
   ```bash
   pytest tests/
   ```

2. **Check coverage regularly**
   ```bash
   pytest --cov=app --cov=data --cov=src --cov-report=term-missing
   ```

3. **Use markers for quick checks**
   ```bash
   pytest -m "not slow"
   ```

4. **Review HTML reports**
   ```bash
   start tests/reports/test_report.html
   ```

5. **Update tests when adding features**
   - New page? Add to `test_streamlit_app.py`
   - New data? Add to `test_data_validation.py`
   - New model? Add to `test_model_validation.py`

## ğŸ“š Further Reading

- [pytest Documentation](https://docs.pytest.org/)
- [pytest-cov Documentation](https://pytest-cov.readthedocs.io/)
- [pytest-html Documentation](https://pytest-html.readthedocs.io/)
- [Coverage.py Documentation](https://coverage.readthedocs.io/)

---

**Last Updated**: 2025-12-12
**Maintainer**: Grid Guardian Development Team
